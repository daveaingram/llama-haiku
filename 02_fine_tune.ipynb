{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train an LLM with custom data\n",
    "\n",
    "In this notebook we will prepare a training dataset and use it to train our custom model.\n",
    "\n",
    "You must have `HUGGINGFACE_API_KEY` in a `.env` file for this to work.\n",
    "\n",
    "First, we'll download a training dataset (only needs to run the first time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "dataset = \"statworx/haiku\"\n",
    "headers = {\"Authorization\": f\"Bearer {os.environ.get('HUGGINGFACE_API_KEY')}\"}\n",
    "API_URL = f\"https://datasets-server.huggingface.co/parquet?dataset={dataset}\"\n",
    "\n",
    "def query():\n",
    "    response = requests.get(API_URL, headers=headers)\n",
    "    return response.json()\n",
    "\n",
    "# get the url to the datafile\n",
    "data = query()\n",
    "url = data[\"parquet_files\"][0][\"url\"]\n",
    "\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "with open('data/haikus.parquet', 'wb') as file:\n",
    "    file.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data\n",
    "\n",
    "Next, we'll load the dataset into a pandas dataframe and prepare a training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>text_phonemes</th>\n",
       "      <th>keywords</th>\n",
       "      <th>keyword_phonemes</th>\n",
       "      <th>gruen_score</th>\n",
       "      <th>text_punc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bfbarry</td>\n",
       "      <td>Delicate savage. / You'll never hold the cinde...</td>\n",
       "      <td>deh|lax|kaxt sae|vaxjh / yuwl neh|ver hhowld d...</td>\n",
       "      <td>cinder</td>\n",
       "      <td>sihn|der</td>\n",
       "      <td>0.639071</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bfbarry</td>\n",
       "      <td>A splash and a cry. / Words pulled from the ri...</td>\n",
       "      <td>ax splaesh aend ax kray / werdz puhld frahm dh...</td>\n",
       "      <td>the riverside</td>\n",
       "      <td>dhax rih|ver|sayd</td>\n",
       "      <td>0.563353</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bfbarry</td>\n",
       "      <td>Steamy, mist rising. / Rocks receiving downwar...</td>\n",
       "      <td>stiy|miy mihst ray|zaxng / raaks rax|siy|vaxng...</td>\n",
       "      <td>mist rising</td>\n",
       "      <td>mihst ray|zaxng</td>\n",
       "      <td>0.538326</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bfbarry</td>\n",
       "      <td>You were broken glass. / But I touched you eve...</td>\n",
       "      <td>yuw wer brow|kaxn glaes / baht ay tahcht yuw i...</td>\n",
       "      <td>broken glass</td>\n",
       "      <td>brow|kaxn glaes</td>\n",
       "      <td>0.703446</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bfbarry</td>\n",
       "      <td>Eyes dance with firelight. / The Moon and I ar...</td>\n",
       "      <td>ayz daens wihdh faxr|layt / dhax muwn aend ay ...</td>\n",
       "      <td>eyes dance</td>\n",
       "      <td>ayz daens</td>\n",
       "      <td>0.830985</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49019</th>\n",
       "      <td>haiku_data_2</td>\n",
       "      <td>Alpine Lake. / Mybreaststrokesshiningarc. / To...</td>\n",
       "      <td>ael|payn leyk mih|brehst|strow|kehsh|hhax|nihn...</td>\n",
       "      <td>toward sunrise</td>\n",
       "      <td>tax|waord sahn|rayz</td>\n",
       "      <td>0.685355</td>\n",
       "      <td>Alpine Lake. Mybreaststrokesshiningarc. Toward...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49020</th>\n",
       "      <td>haiku_data_2</td>\n",
       "      <td>Spruce Woods. / Fireweed filling. / The vacancy.</td>\n",
       "      <td>spruws wuhdz fay|er|wiyd fih|laxng dhax vey|ka...</td>\n",
       "      <td>woods</td>\n",
       "      <td>wuhdz</td>\n",
       "      <td>0.568974</td>\n",
       "      <td>Spruce Woods. Fireweed filling. The vacancy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49021</th>\n",
       "      <td>haiku_data_2</td>\n",
       "      <td>Corrugated sun. / Chilies and laundry. / In ro...</td>\n",
       "      <td>kao|rax|gey|taxd sahn chih|liyz aend laon|driy...</td>\n",
       "      <td>sun chilies</td>\n",
       "      <td>sahn chih|liyz</td>\n",
       "      <td>0.551056</td>\n",
       "      <td>Corrugated sun. Chilies and laundry. In roofto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49022</th>\n",
       "      <td>haiku_data_2</td>\n",
       "      <td>Home from war. / We ease out. / The champagne ...</td>\n",
       "      <td>hhowm frahm waor wiy iyz awt dhax shaxm|peyn k...</td>\n",
       "      <td>home</td>\n",
       "      <td>hhowm</td>\n",
       "      <td>0.697112</td>\n",
       "      <td>Home from war. We ease out. The champagne corks.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49023</th>\n",
       "      <td>haiku_data_2</td>\n",
       "      <td>'</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>ehn</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49024 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             source                                               text  \\\n",
       "0           bfbarry  Delicate savage. / You'll never hold the cinde...   \n",
       "1           bfbarry  A splash and a cry. / Words pulled from the ri...   \n",
       "2           bfbarry  Steamy, mist rising. / Rocks receiving downwar...   \n",
       "3           bfbarry  You were broken glass. / But I touched you eve...   \n",
       "4           bfbarry  Eyes dance with firelight. / The Moon and I ar...   \n",
       "...             ...                                                ...   \n",
       "49019  haiku_data_2  Alpine Lake. / Mybreaststrokesshiningarc. / To...   \n",
       "49020  haiku_data_2   Spruce Woods. / Fireweed filling. / The vacancy.   \n",
       "49021  haiku_data_2  Corrugated sun. / Chilies and laundry. / In ro...   \n",
       "49022  haiku_data_2  Home from war. / We ease out. / The champagne ...   \n",
       "49023  haiku_data_2                                                  '   \n",
       "\n",
       "                                           text_phonemes        keywords  \\\n",
       "0      deh|lax|kaxt sae|vaxjh / yuwl neh|ver hhowld d...          cinder   \n",
       "1      ax splaesh aend ax kray / werdz puhld frahm dh...   the riverside   \n",
       "2      stiy|miy mihst ray|zaxng / raaks rax|siy|vaxng...     mist rising   \n",
       "3      yuw wer brow|kaxn glaes / baht ay tahcht yuw i...    broken glass   \n",
       "4      ayz daens wihdh faxr|layt / dhax muwn aend ay ...      eyes dance   \n",
       "...                                                  ...             ...   \n",
       "49019  ael|payn leyk mih|brehst|strow|kehsh|hhax|nihn...  toward sunrise   \n",
       "49020  spruws wuhdz fay|er|wiyd fih|laxng dhax vey|ka...           woods   \n",
       "49021  kao|rax|gey|taxd sahn chih|liyz aend laon|driy...     sun chilies   \n",
       "49022  hhowm frahm waor wiy iyz awt dhax shaxm|peyn k...            home   \n",
       "49023                                                                  N   \n",
       "\n",
       "          keyword_phonemes  gruen_score  \\\n",
       "0                 sihn|der     0.639071   \n",
       "1        dhax rih|ver|sayd     0.563353   \n",
       "2          mihst ray|zaxng     0.538326   \n",
       "3          brow|kaxn glaes     0.703446   \n",
       "4                ayz daens     0.830985   \n",
       "...                    ...          ...   \n",
       "49019  tax|waord sahn|rayz     0.685355   \n",
       "49020                wuhdz     0.568974   \n",
       "49021       sahn chih|liyz     0.551056   \n",
       "49022                hhowm     0.697112   \n",
       "49023                  ehn     0.625000   \n",
       "\n",
       "                                               text_punc  \n",
       "0                                                   None  \n",
       "1                                                   None  \n",
       "2                                                   None  \n",
       "3                                                   None  \n",
       "4                                                   None  \n",
       "...                                                  ...  \n",
       "49019  Alpine Lake. Mybreaststrokesshiningarc. Toward...  \n",
       "49020       Spruce Woods. Fireweed filling. The vacancy.  \n",
       "49021  Corrugated sun. Chilies and laundry. In roofto...  \n",
       "49022   Home from war. We ease out. The champagne corks.  \n",
       "49023                                                  '  \n",
       "\n",
       "[49024 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "haikus = pd.read_parquet(\"data/haikus.parquet\")\n",
    "haikus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Haiku format:\n",
      "My man is sleeping. / So peaceful I'm going to. / Get up, cook breakfast.\n",
      "\n",
      "With new-lines:\n",
      "My man is sleeping.\n",
      "So peaceful I'm going to.\n",
      "Get up, cook breakfast.\n",
      "\n",
      "Train whistle.\n",
      "A blackbird hops.\n",
      "Along its notes.\n",
      "\n",
      "Winter's breathy joke.\n",
      "Exploring fragilities.\n",
      "Frigid hearts break hard.\n",
      "\n",
      "Butterfly wings.\n",
      "Their so loud flapping.\n",
      "In a temple's Silence.\n",
      "\n",
      "Summer sky.\n",
      "My father counts the black faces.\n",
      "On my road.\n"
     ]
    }
   ],
   "source": [
    "# Let's take just a random sample of 5000 of these.\n",
    "haikus_text = haikus[\"text\"].sample(100)\n",
    "\n",
    "# print the first haiku\n",
    "print(\"Original Haiku format:\")\n",
    "print(haikus_text.iloc[0])\n",
    "\n",
    "# Add newlines\n",
    "haikus_text = haikus_text.str.replace(\" / \", \"\\n\")\n",
    "print(\"\\nWith new-lines:\")\n",
    "print(haikus_text.iloc[0])\n",
    "\n",
    "# Look at 4 more of them\n",
    "for i in range(1, 5):\n",
    "    print(\"\\n\" + haikus_text.iloc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uh-oh!\n",
    "\n",
    "They don't all have the standard format. Time to make sure our dataset is really clean before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>text_phonemes</th>\n",
       "      <th>keywords</th>\n",
       "      <th>keyword_phonemes</th>\n",
       "      <th>gruen_score</th>\n",
       "      <th>text_punc</th>\n",
       "      <th>valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>bfbarry</td>\n",
       "      <td>Your coldness burns me. / You stab me with ici...</td>\n",
       "      <td>yaor kowld|naxs bernz miy / yuw staeb miy wihd...</td>\n",
       "      <td>icicles</td>\n",
       "      <td>ay|sax|kaxlz</td>\n",
       "      <td>0.891561</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>bfbarry</td>\n",
       "      <td>Darkness falls quickly. / The sun sets behind ...</td>\n",
       "      <td>daark|naxs faolz kwih|kliy / dhax sahn sehts b...</td>\n",
       "      <td>darkness falls</td>\n",
       "      <td>daark|naxs faolz</td>\n",
       "      <td>0.885124</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2884</th>\n",
       "      <td>bfbarry</td>\n",
       "      <td>Rain falls from the sky. / Your head tilts up ...</td>\n",
       "      <td>reyn faolz frahm dhax skay / yaor hhehd tihlts...</td>\n",
       "      <td>rain falls</td>\n",
       "      <td>reyn faolz</td>\n",
       "      <td>0.877835</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14525</th>\n",
       "      <td>twaiku</td>\n",
       "      <td>Joe Thomas knows how. / You lost your virginit...</td>\n",
       "      <td>jhow taa|maxs nowz hhaw / yuw laost yaor ver|j...</td>\n",
       "      <td>your virginity</td>\n",
       "      <td>yaor ver|jhih|nax|tiy</td>\n",
       "      <td>0.877294</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5739</th>\n",
       "      <td>bfbarry</td>\n",
       "      <td>Now, will you begin? / To do what you want to ...</td>\n",
       "      <td>naw wihl yuw bax|gihn / tax duw waht yuw waant...</td>\n",
       "      <td>always dying</td>\n",
       "      <td>aol|weyz day|axng</td>\n",
       "      <td>0.875700</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29508</th>\n",
       "      <td>haiku_data_1</td>\n",
       "      <td>Enough farmhouse. / A vine wrapped around. / T...</td>\n",
       "      <td>ih|nahf faarm|hhaws ey vayn raept er|awnd dhax...</td>\n",
       "      <td>vine wrapped</td>\n",
       "      <td>vayn raept</td>\n",
       "      <td>0.394552</td>\n",
       "      <td>Enough farmhouse. A vine wrapped around. The w...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36281</th>\n",
       "      <td>haiku_data_1</td>\n",
       "      <td>Lightstudded ferry. / Passes in the starless n...</td>\n",
       "      <td>layt|stax|daxd feh|riy pae|saxz ihn dhax staar...</td>\n",
       "      <td>night</td>\n",
       "      <td>nayt</td>\n",
       "      <td>0.393787</td>\n",
       "      <td>Lightstudded ferry. Passes in the starless nig...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39837</th>\n",
       "      <td>haiku_data_1</td>\n",
       "      <td>Aversed home. / An old life laid to rest. / Am...</td>\n",
       "      <td>ae|verst hhowm axn owld layf leyd tax rehst ax...</td>\n",
       "      <td>weeds</td>\n",
       "      <td>wiydz</td>\n",
       "      <td>0.376451</td>\n",
       "      <td>Aversed home. An old life laid to rest. Among ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29655</th>\n",
       "      <td>haiku_data_1</td>\n",
       "      <td>Our passing breeze. / A do not disturb sign sw...</td>\n",
       "      <td>aw|er pae|saxng briyz ey duw naat dax|sterb sa...</td>\n",
       "      <td>breeze</td>\n",
       "      <td>briyz</td>\n",
       "      <td>0.371297</td>\n",
       "      <td>Our passing breeze. A do not disturb sign swin...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42520</th>\n",
       "      <td>haiku_data_2</td>\n",
       "      <td>Our passing breeze. / A do not disturb sign sw...</td>\n",
       "      <td>aw|er pae|saxng briyz ey duw naat dax|sterb sa...</td>\n",
       "      <td>breeze</td>\n",
       "      <td>briyz</td>\n",
       "      <td>0.371297</td>\n",
       "      <td>Our passing breeze. A do not disturb sign swin...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4215 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             source                                               text  \\\n",
       "2056        bfbarry  Your coldness burns me. / You stab me with ici...   \n",
       "1313        bfbarry  Darkness falls quickly. / The sun sets behind ...   \n",
       "2884        bfbarry  Rain falls from the sky. / Your head tilts up ...   \n",
       "14525        twaiku  Joe Thomas knows how. / You lost your virginit...   \n",
       "5739        bfbarry  Now, will you begin? / To do what you want to ...   \n",
       "...             ...                                                ...   \n",
       "29508  haiku_data_1  Enough farmhouse. / A vine wrapped around. / T...   \n",
       "36281  haiku_data_1  Lightstudded ferry. / Passes in the starless n...   \n",
       "39837  haiku_data_1  Aversed home. / An old life laid to rest. / Am...   \n",
       "29655  haiku_data_1  Our passing breeze. / A do not disturb sign sw...   \n",
       "42520  haiku_data_2  Our passing breeze. / A do not disturb sign sw...   \n",
       "\n",
       "                                           text_phonemes        keywords  \\\n",
       "2056   yaor kowld|naxs bernz miy / yuw staeb miy wihd...         icicles   \n",
       "1313   daark|naxs faolz kwih|kliy / dhax sahn sehts b...  darkness falls   \n",
       "2884   reyn faolz frahm dhax skay / yaor hhehd tihlts...      rain falls   \n",
       "14525  jhow taa|maxs nowz hhaw / yuw laost yaor ver|j...  your virginity   \n",
       "5739   naw wihl yuw bax|gihn / tax duw waht yuw waant...    always dying   \n",
       "...                                                  ...             ...   \n",
       "29508  ih|nahf faarm|hhaws ey vayn raept er|awnd dhax...    vine wrapped   \n",
       "36281  layt|stax|daxd feh|riy pae|saxz ihn dhax staar...           night   \n",
       "39837  ae|verst hhowm axn owld layf leyd tax rehst ax...           weeds   \n",
       "29655  aw|er pae|saxng briyz ey duw naat dax|sterb sa...          breeze   \n",
       "42520  aw|er pae|saxng briyz ey duw naat dax|sterb sa...          breeze   \n",
       "\n",
       "            keyword_phonemes  gruen_score  \\\n",
       "2056            ay|sax|kaxlz     0.891561   \n",
       "1313        daark|naxs faolz     0.885124   \n",
       "2884              reyn faolz     0.877835   \n",
       "14525  yaor ver|jhih|nax|tiy     0.877294   \n",
       "5739       aol|weyz day|axng     0.875700   \n",
       "...                      ...          ...   \n",
       "29508             vayn raept     0.394552   \n",
       "36281                   nayt     0.393787   \n",
       "39837                  wiydz     0.376451   \n",
       "29655                  briyz     0.371297   \n",
       "42520                  briyz     0.371297   \n",
       "\n",
       "                                               text_punc  valid  \n",
       "2056                                                None   True  \n",
       "1313                                                None   True  \n",
       "2884                                                None   True  \n",
       "14525                                               None   True  \n",
       "5739                                                None   True  \n",
       "...                                                  ...    ...  \n",
       "29508  Enough farmhouse. A vine wrapped around. The w...   True  \n",
       "36281  Lightstudded ferry. Passes in the starless nig...   True  \n",
       "39837  Aversed home. An old life laid to rest. Among ...   True  \n",
       "29655  Our passing breeze. A do not disturb sign swin...   True  \n",
       "42520  Our passing breeze. A do not disturb sign swin...   True  \n",
       "\n",
       "[4215 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import syllables\n",
    "\n",
    "def validate_haiku(haiku):\n",
    "    syllable_count = [syllables.estimate(line) for line in haiku.split(\" / \")]\n",
    "    if syllable_count == [5, 7, 5]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "haikus[\"valid\"] = haikus[\"text\"].apply(validate_haiku)\n",
    "\n",
    "# now filter down to only the \"valid\" ones\n",
    "valid_haikus = haikus[haikus[\"valid\"]==True]\n",
    "valid_haikus.sort_values(\"gruen_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good enough, let's train!\n",
    "\n",
    "Next up we'll use the \"text\" and \"keywords\" columns to construct a training dataset to use for training our model with this filtered set of haikus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version 2.1.2 available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dave/miniconda3/envs/llm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated new fontManager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 638/638 [00:00<00:00, 287kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting generation max_new_tokens to 16384 to correspond with the max sequence length assigned to the output feature or the global max sequence length. This will ensure that the correct number of tokens are generated at inference time. To override this behavior, set `generation.max_new_tokens` to a different value in your Ludwig config.\n",
      "\n",
      "╒════════════════════════╕\n",
      "│ EXPERIMENT DESCRIPTION │\n",
      "╘════════════════════════╛\n",
      "\n",
      "╒══════════════════╤══════════════════════════════════════════════════════════════════════════════════════╕\n",
      "│ Experiment name  │ api_experiment                                                                       │\n",
      "├──────────────────┼──────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ Model name       │ run                                                                                  │\n",
      "├──────────────────┼──────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ Output directory │ /home/dave/code/llama-haiku/results/api_experiment_run                               │\n",
      "├──────────────────┼──────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ ludwig_version   │ '0.9.1'                                                                              │\n",
      "├──────────────────┼──────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ command          │ ('/home/dave/miniconda3/envs/llm/lib/python3.9/site-packages/ipykernel_launcher.py ' │\n",
      "│                  │  '--f=/home/dave/.local/share/jupyter/runtime/kernel-v2-89127TuzzzQVYjI4f.json')     │\n",
      "├──────────────────┼──────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ commit_hash      │ '7ed9a6b12eef'                                                                       │\n",
      "├──────────────────┼──────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ random_seed      │ 42                                                                                   │\n",
      "├──────────────────┼──────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ data_format      │ \"<class 'pandas.core.frame.DataFrame'>\"                                              │\n",
      "├──────────────────┼──────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ torch_version    │ '2.1.2+cu121'                                                                        │\n",
      "├──────────────────┼──────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ compute          │ {   'arch_list': [   'sm_50',                                                        │\n",
      "│                  │                      'sm_60',                                                        │\n",
      "│                  │                      'sm_70',                                                        │\n",
      "│                  │                      'sm_75',                                                        │\n",
      "│                  │                      'sm_80',                                                        │\n",
      "│                  │                      'sm_86',                                                        │\n",
      "│                  │                      'sm_90'],                                                       │\n",
      "│                  │     'devices': {   0: {   'device_capability': (8, 9),                               │\n",
      "│                  │                           'device_properties': \"_CudaDeviceProperties(name='NVIDIA \" │\n",
      "│                  │                                                \"GeForce RTX 4090', major=8, \"        │\n",
      "│                  │                                                'minor=9, total_memory=24563MB, '     │\n",
      "│                  │                                                'multi_processor_count=128)',         │\n",
      "│                  │                           'gpu_type': 'NVIDIA GeForce RTX 4090'}},                   │\n",
      "│                  │     'gencode_flags': '-gencode compute=compute_50,code=sm_50 -gencode '              │\n",
      "│                  │                      'compute=compute_60,code=sm_60 -gencode '                       │\n",
      "│                  │                      'compute=compute_70,code=sm_70 -gencode '                       │\n",
      "│                  │                      'compute=compute_75,code=sm_75 -gencode '                       │\n",
      "│                  │                      'compute=compute_80,code=sm_80 -gencode '                       │\n",
      "│                  │                      'compute=compute_86,code=sm_86 -gencode '                       │\n",
      "│                  │                      'compute=compute_90,code=sm_90',                                │\n",
      "│                  │     'gpus_per_node': 1,                                                              │\n",
      "│                  │     'num_nodes': 1}                                                                  │\n",
      "╘══════════════════╧══════════════════════════════════════════════════════════════════════════════════════╛\n",
      "\n",
      "╒═══════════════╕\n",
      "│ LUDWIG CONFIG │\n",
      "╘═══════════════╛\n",
      "\n",
      "User-specified config (with upgrades):\n",
      "\n",
      "{   'adapter': {'type': 'lora'},\n",
      "    'backend': {'type': 'local'},\n",
      "    'base_model': 'HuggingFaceH4/zephyr-7b-beta',\n",
      "    'input_features': [{'name': 'keywords', 'type': 'text'}],\n",
      "    'ludwig_version': '0.9.1',\n",
      "    'model_type': 'llm',\n",
      "    'output_features': [{'name': 'text', 'type': 'text'}],\n",
      "    'quantization': {'bits': 4},\n",
      "    'trainer': {   'batch_size': 2,\n",
      "                   'epochs': 3,\n",
      "                   'gradient_accumulation_steps': 8,\n",
      "                   'learning_rate': 0.0003,\n",
      "                   'learning_rate_scheduler': {'warmup_fraction': 0.01},\n",
      "                   'type': 'finetune'}}\n",
      "\n",
      "Full config saved to:\n",
      "/home/dave/code/llama-haiku/results/api_experiment_run/api_experiment/model/model_hyperparameters.json\n",
      "\n",
      "╒═══════════════╕\n",
      "│ PREPROCESSING │\n",
      "╘═══════════════╛\n",
      "\n",
      "No cached dataset found at /home/dave/code/llama-haiku/d66036b8af3f11eea87be55baf3cf3ab.training.hdf5. Preprocessing the dataset.\n",
      "Using full dataframe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataset (it may take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 1.43k/1.43k [00:00<00:00, 596kB/s]\n",
      "tokenizer.model: 100%|██████████| 493k/493k [00:00<00:00, 10.8MB/s]\n",
      "added_tokens.json: 100%|██████████| 42.0/42.0 [00:00<00:00, 49.9kB/s]\n",
      "special_tokens_map.json: 100%|██████████| 168/168 [00:00<00:00, 174kB/s]\n",
      "tokenizer.json: 100%|██████████| 1.80M/1.80M [00:00<00:00, 27.6MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded HuggingFace implementation of HuggingFaceH4/zephyr-7b-beta tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of feature 'keywords': 9 (without start and stop symbols)\n",
      "Max sequence length is 9 for feature 'keywords'\n",
      "Loaded HuggingFace implementation of HuggingFaceH4/zephyr-7b-beta tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of feature 'text': 33 (without start and stop symbols)\n",
      "Max sequence length is 33 for feature 'text'\n",
      "Loaded HuggingFace implementation of HuggingFaceH4/zephyr-7b-beta tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded HuggingFace implementation of HuggingFaceH4/zephyr-7b-beta tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataset: DONE\n",
      "Writing preprocessed training set cache to /home/dave/code/llama-haiku/d66036b8af3f11eea87be55baf3cf3ab.training.hdf5\n",
      "Writing preprocessed validation set cache to /home/dave/code/llama-haiku/d66036b8af3f11eea87be55baf3cf3ab.validation.hdf5\n",
      "Writing preprocessed test set cache to /home/dave/code/llama-haiku/d66036b8af3f11eea87be55baf3cf3ab.test.hdf5\n",
      "Writing train set metadata to /home/dave/code/llama-haiku/d66036b8af3f11eea87be55baf3cf3ab.meta.json\n",
      "\n",
      "Dataset Statistics\n",
      "╒════════════╤═══════════════╤════════════════════╕\n",
      "│ Dataset    │   Size (Rows) │ Size (In Memory)   │\n",
      "╞════════════╪═══════════════╪════════════════════╡\n",
      "│ Training   │          2951 │ 691.77 Kb          │\n",
      "├────────────┼───────────────┼────────────────────┤\n",
      "│ Validation │           421 │ 98.80 Kb           │\n",
      "├────────────┼───────────────┼────────────────────┤\n",
      "│ Test       │           843 │ 197.70 Kb          │\n",
      "╘════════════╧═══════════════╧════════════════════╛\n",
      "\n",
      "╒═══════╕\n",
      "│ MODEL │\n",
      "╘═══════╛\n",
      "\n",
      "Warnings and other logs:\n",
      "Loading large language model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors.index.json: 100%|██████████| 23.9k/23.9k [00:00<00:00, 9.75MB/s]\n",
      "model-00001-of-00008.safetensors: 100%|██████████| 1.89G/1.89G [00:17<00:00, 111MB/s]\n",
      "model-00002-of-00008.safetensors: 100%|██████████| 1.95G/1.95G [00:17<00:00, 111MB/s]\n",
      "model-00003-of-00008.safetensors: 100%|██████████| 1.98G/1.98G [00:18<00:00, 106MB/s]\n",
      "model-00004-of-00008.safetensors: 100%|██████████| 1.95G/1.95G [00:18<00:00, 104MB/s] \n",
      "model-00005-of-00008.safetensors: 100%|██████████| 1.98G/1.98G [00:19<00:00, 104MB/s]\n",
      "model-00006-of-00008.safetensors: 100%|██████████| 1.95G/1.95G [00:18<00:00, 105MB/s]\n",
      "model-00007-of-00008.safetensors: 100%|██████████| 1.98G/1.98G [00:19<00:00, 103MB/s]\n",
      "model-00008-of-00008.safetensors: 100%|██████████| 816M/816M [00:07<00:00, 109MB/s]\n",
      "Downloading shards: 100%|██████████| 8/8 [02:16<00:00, 17.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:04<00:00,  1.94it/s]\n",
      "generation_config.json: 100%|██████████| 111/111 [00:00<00:00, 130kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded HuggingFace implementation of HuggingFaceH4/zephyr-7b-beta tokenizer\n",
      "==================================================\n",
      "Trainable Parameter Summary For Fine-Tuning\n",
      "Fine-tuning with adapter: lora\n",
      "trainable params: 3,407,872 || all params: 7,245,139,968 || trainable%: 0.04703666202518836\n",
      "==================================================\n",
      "\n",
      "╒══════════╕\n",
      "│ TRAINING │\n",
      "╘══════════╛\n",
      "\n",
      "Creating fresh model training run.\n",
      "Training for 4428 step(s), approximately 3 epoch(s).\n",
      "Early stopping policy: 5 round(s) of evaluation, or 7380 step(s), approximately 5 epoch(s).\n",
      "\n",
      "Starting with step 0, epoch: 0\n",
      "Training:  33%|███▎      | 1475/4428 [03:13<06:26,  7.63it/s, loss=0.325]Last batch in epoch only has 1 sample and will be dropped.\n",
      "Last batch in epoch only has 1 sample and will be dropped.\n",
      "Last batch in epoch only has 1 sample and will be dropped.\n",
      "Training:  33%|███▎      | 1476/4428 [03:13<07:27,  6.60it/s, loss=0.277]\n",
      "Running evaluation for step: 1476, epoch: 1\n",
      "Evaluation valid: 100%|██████████| 211/211 [00:15<00:00, 13.92it/s]\n",
      "Input: heart feels\n",
      "Output: The My heart feels so. / Now sure, to, but. / I than before.\n",
      "--------------------\n",
      "Input: naked petals\n",
      "Output: < I naked'ossoms. / Nveling naked naked petals. / Toure out the sun. dearad.\n",
      "--------------------\n",
      "Input: get cuter\n",
      "Output: < I you get cuter? / As they get talking to them. / Or is that just me.\n",
      "--------------------\n",
      "Input: fat shaming\n",
      "Output: < I know what I'. / A, I shaming, but. / I a world?.\n",
      "--------------------\n",
      "Input: his karma\n",
      "Output: < I man, big.. / Iseds to be his karma.. / Are' him happen.\n",
      "--------------------\n",
      "Evaluation test : 100%|██████████| 422/422 [00:29<00:00, 14.48it/s]\n",
      "Input: awaited tea\n",
      "Output: < I awaited tea. / The' me cup with warmth warmth. / And is morning cold.\n",
      "--------------------\n",
      "Input: on\n",
      "Output: < Ino what I to?. / About this, Aking. / Shuff on myapchat.\n",
      "--------------------\n",
      "Input: music\n",
      "Output: < Iy of the. / The music in music music. / In to the.\n",
      "--------------------\n",
      "Input: human rights\n",
      "Output: < I' don. / Thely is a humanach. / Of human human rights.\n",
      "--------------------\n",
      "Input: mood\n",
      "Output: The Iitting in the bed. / Watchening to the music and. / Feinking a my mood.\n",
      "--------------------\n",
      "Evaluation took 44.9526s\n",
      "\n",
      "╒═══════════════════════╤════════════╤══════════════╤════════════╕\n",
      "│                       │      train │   validation │       test │\n",
      "╞═══════════════════════╪════════════╪══════════════╪════════════╡\n",
      "│ bleu                  │     0.0000 │       0.1307 │     0.1350 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ char_error_rate       │     0.4493 │       0.4727 │     0.4730 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ loss                  │     2.2144 │       1.9991 │     2.0562 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ next_token_perplexity │ 20785.3027 │   19101.8066 │ 19187.4414 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ perplexity            │ 31998.8145 │   31997.7461 │ 31993.0762 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rouge1_fmeasure       │     0.3841 │       0.4422 │     0.4304 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rouge1_precision      │     0.4091 │       0.4602 │     0.4490 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rouge1_recall         │     0.3622 │       0.4275 │     0.4155 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rouge2_fmeasure       │     0.0476 │       0.1797 │     0.1770 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rouge2_precision      │     0.0500 │       0.1869 │     0.1847 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rouge2_recall         │     0.0455 │       0.1738 │     0.1710 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rougeL_fmeasure       │     0.3424 │       0.4133 │     0.4079 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rougeL_precision      │     0.3636 │       0.4299 │     0.4255 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rougeL_recall         │     0.3237 │       0.3997 │     0.3939 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rougeLsum_fmeasure    │     0.3841 │       0.4344 │     0.4251 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rougeLsum_precision   │     0.4091 │       0.4519 │     0.4434 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rougeLsum_recall      │     0.3622 │       0.4200 │     0.4105 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ sequence_accuracy     │     0.0000 │       0.0000 │     0.0000 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ token_accuracy        │     0.0000 │       0.0000 │     0.0002 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ word_error_rate       │     0.6552 │       0.6446 │     0.6457 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ combined_loss         │     2.2144 │       1.9991 │     2.0562 │\n",
      "╘═══════════════════════╧════════════╧══════════════╧════════════╛\n",
      "Evaluation validation metric: 'text' 'loss' improved.\n",
      "'text' 'loss' decreased by inf.\n",
      "New best model saved.\n",
      "\n",
      "Training:  67%|██████▋   | 2950/4428 [07:07<03:05,  7.96it/s, loss=0.23]    Last batch in epoch only has 1 sample and will be dropped.\n",
      "Last batch in epoch only has 1 sample and will be dropped.\n",
      "Last batch in epoch only has 1 sample and will be dropped.\n",
      "Training:  67%|██████▋   | 2952/4428 [07:07<03:28,  7.08it/s, loss=0.131]\n",
      "Running evaluation for step: 2952, epoch: 2\n",
      "Evaluation valid: 100%|██████████| 211/211 [00:13<00:00, 15.33it/s]\n",
      "Input: heart feels\n",
      "Output: The My heart feels so. / Now gonna, to, but. / It than before.\n",
      "--------------------\n",
      "Input: naked petals\n",
      "Output: < N naked bloossoms. / Nfurling naked naked petals. / Forure out the moon. lightad.\n",
      "--------------------\n",
      "Input: get cuter\n",
      "Output: < I you ever cuter? / As they get trying to them. / Or is that just me.\n",
      "--------------------\n",
      "Input: fat shaming\n",
      "Output: < I know what I'. / A, my shaming, I. / I a coinc joke.\n",
      "--------------------\n",
      "Input: his karma\n",
      "Output: < I man, big.. / Willeds to be his karma up. / All' him happen.\n",
      "--------------------\n",
      "Evaluation test : 100%|██████████| 422/422 [00:27<00:00, 15.24it/s]\n",
      "Input: awaited tea\n",
      "Output: < I awaited tea. / The are me cup with warmth warmth. / I is evening cold.\n",
      "--------------------\n",
      "Input: on\n",
      "Output: < Ino what I I.. / About this, Kingking. / Passuff on myapchat.\n",
      "--------------------\n",
      "Input: music\n",
      "Output: < Iy of music. / The music of music music. / In to the.\n",
      "--------------------\n",
      "Input: human rights\n",
      "Output: < I' don. / Thatly is a humanach. / Of human human rights.\n",
      "--------------------\n",
      "Input: mood\n",
      "Output: < Iitting in the couch. / Inening to the music and. / Chinking a my mood.\n",
      "--------------------\n",
      "Evaluation took 41.9896s\n",
      "\n",
      "╒═══════════════════════╤════════════╤══════════════╤════════════╕\n",
      "│                       │      train │   validation │       test │\n",
      "╞═══════════════════════╪════════════╪══════════════╪════════════╡\n",
      "│ bleu                  │     0.5796 │       0.1438 │     0.1378 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ char_error_rate       │     0.3611 │       0.4809 │     0.4791 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ loss                  │     1.0511 │       1.9761 │     2.0292 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ next_token_perplexity │ 17074.3516 │   18877.3535 │ 18947.3594 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ perplexity            │ 32000.6113 │   31997.2852 │ 31992.5273 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rouge1_fmeasure       │     0.5962 │       0.4440 │     0.4350 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rouge1_precision      │     0.5962 │       0.4533 │     0.4458 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rouge1_recall         │     0.5962 │       0.4368 │     0.4266 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rouge2_fmeasure       │     0.4280 │       0.1866 │     0.1847 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rouge2_precision      │     0.4280 │       0.1904 │     0.1895 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rouge2_recall         │     0.4280 │       0.1838 │     0.1810 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rougeL_fmeasure       │     0.5962 │       0.4191 │     0.4116 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rougeL_precision      │     0.5962 │       0.4276 │     0.4219 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rougeL_recall         │     0.5962 │       0.4124 │     0.4036 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rougeLsum_fmeasure    │     0.5962 │       0.4389 │     0.4315 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rougeLsum_precision   │     0.5962 │       0.4480 │     0.4423 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rougeLsum_recall      │     0.5962 │       0.4318 │     0.4232 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ sequence_accuracy     │     0.0000 │       0.0000 │     0.0000 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ token_accuracy        │     0.0000 │       0.0000 │     0.0002 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ word_error_rate       │     0.3793 │       0.6366 │     0.6398 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ combined_loss         │     1.0511 │       1.9761 │     2.0292 │\n",
      "╘═══════════════════════╧════════════╧══════════════╧════════════╛\n",
      "Evaluation validation metric: 'text' 'loss' improved.\n",
      "'text' 'loss' decreased by 0.023.\n",
      "New best model saved.\n",
      "\n",
      "Training: 100%|█████████▉| 4425/4428 [11:00<00:00,  7.73it/s, loss=0.14]   Last batch in epoch only has 1 sample and will be dropped.\n",
      "Last batch in epoch only has 1 sample and will be dropped.\n",
      "Last batch in epoch only has 1 sample and will be dropped.\n",
      "Training: 100%|██████████| 4428/4428 [11:01<00:00,  7.15it/s, loss=0.131]\n",
      "Running evaluation for step: 4428, epoch: 3\n",
      "Evaluation valid: 100%|██████████| 211/211 [00:13<00:00, 15.45it/s]\n",
      "Input: heart feels\n",
      "Output: The My heart feels heavy. / Now gonna, to, but. / I than before.\n",
      "--------------------\n",
      "Input: naked petals\n",
      "Output: < N naked'ossoms. / Nfurling naked naked petals. / Forure out the rain. dearad.\n",
      "--------------------\n",
      "Input: get cuter\n",
      "Output: < I you get cuter? / As they get talking to them. / I is it just me?\n",
      "--------------------\n",
      "Input: fat shaming\n",
      "Output: < I know what I'. / On on my shaming, I. / I a great??\n",
      "--------------------\n",
      "Input: his karma\n",
      "Output: < I man, big.. / Weds to be his karma,. / Need' it happen.\n",
      "--------------------\n",
      "Evaluation test : 100%|██████████| 422/422 [00:27<00:00, 15.39it/s]\n",
      "Input: awaited tea\n",
      "Output: < I awaited tea. / The are me cup and warmth.. / I is' cold.\n",
      "--------------------\n",
      "Input: on\n",
      "Output: < Ino what I I put? / About this, Bearking. / Passuff on myapchat.\n",
      "--------------------\n",
      "Input: music\n",
      "Output: < Iy of the. / The music of music song. / In to the.\n",
      "--------------------\n",
      "Input: human rights\n",
      "Output: < I' don. / Thely is a humanach. / Of human human rights.\n",
      "--------------------\n",
      "Input: mood\n",
      "Output: The Iitting in the bed. / Inening to the school and. / Chinking my my mood.\n",
      "--------------------\n",
      "Evaluation took 41.6020s\n",
      "\n",
      "╒═══════════════════════╤════════════╤══════════════╤════════════╕\n",
      "│                       │      train │   validation │       test │\n",
      "╞═══════════════════════╪════════════╪══════════════╪════════════╡\n",
      "│ bleu                  │     0.3161 │       0.1382 │     0.1428 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ char_error_rate       │     0.3265 │       0.4832 │     0.4797 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ loss                  │     1.0498 │       2.0338 │     2.0818 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ next_token_perplexity │ 16311.1943 │   18707.2188 │ 18785.0605 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ perplexity            │ 31996.7383 │   31998.2031 │ 31993.6875 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rouge1_fmeasure       │     0.5959 │       0.4347 │     0.4272 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rouge1_precision      │     0.6190 │       0.4454 │     0.4391 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rouge1_recall         │     0.5744 │       0.4263 │     0.4178 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rouge2_fmeasure       │     0.3655 │       0.1785 │     0.1805 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rouge2_precision      │     0.3811 │       0.1828 │     0.1857 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rouge2_recall         │     0.3512 │       0.1753 │     0.1765 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rougeL_fmeasure       │     0.5959 │       0.4102 │     0.4055 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rougeL_precision      │     0.6190 │       0.4202 │     0.4168 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rougeL_recall         │     0.5744 │       0.4024 │     0.3966 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rougeLsum_fmeasure    │     0.5959 │       0.4290 │     0.4234 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rougeLsum_precision   │     0.6190 │       0.4396 │     0.4351 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ rougeLsum_recall      │     0.5744 │       0.4208 │     0.4141 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ sequence_accuracy     │     0.0000 │       0.0000 │     0.0000 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ token_accuracy        │     0.0000 │       0.0000 │     0.0002 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ word_error_rate       │     0.5333 │       0.6451 │     0.6411 │\n",
      "├───────────────────────┼────────────┼──────────────┼────────────┤\n",
      "│ combined_loss         │     1.0498 │       2.0338 │     2.0818 │\n",
      "╘═══════════════════════╧════════════╧══════════════╧════════════╛\n",
      "Last improvement of text validation loss happened 1476 step(s) ago.\n",
      "\n",
      "Training: 100%|██████████| 4428/4428 [11:42<00:00,  6.30it/s, loss=0.131]\n",
      "\n",
      "╒═════════════════╕\n",
      "│ TRAINING REPORT │\n",
      "╘═════════════════╛\n",
      "\n",
      "╒══════════════════════════════╤════════════════════╕\n",
      "│ Validation feature           │ text               │\n",
      "├──────────────────────────────┼────────────────────┤\n",
      "│ Validation metric            │ loss               │\n",
      "├──────────────────────────────┼────────────────────┤\n",
      "│ Best model step              │ 2952               │\n",
      "├──────────────────────────────┼────────────────────┤\n",
      "│ Best model epoch             │ 3                  │\n",
      "├──────────────────────────────┼────────────────────┤\n",
      "│ Best model's validation loss │ 1.976143479347229  │\n",
      "├──────────────────────────────┼────────────────────┤\n",
      "│ Best model's test loss       │ 2.0291991233825684 │\n",
      "╘══════════════════════════════╧════════════════════╛\n",
      "\n",
      "Finished: api_experiment_run\n",
      "Saved to: /home/dave/code/llama-haiku/results/api_experiment_run\n",
      "\n",
      "╒══════════╕\n",
      "│ FINISHED │\n",
      "╘══════════╛\n",
      "\n",
      "contents of output directory: /home/dave/code/llama-haiku/results/api_experiment_run\n",
      "\t description.json\n",
      "\t model\n",
      "\t training_statistics.json\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import yaml\n",
    "\n",
    "from ludwig.api import LudwigModel\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "<|system|>\n",
    "You are a haiku writer and respond to all questions with a haiku</s>\n",
    "<|user|>\n",
    "Tell me about {keywords}</s>\n",
    "<|assistant|>\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "# Build out the configuration\n",
    "config = yaml.safe_load(\n",
    "    \"\"\"\n",
    "model_type: llm\n",
    "base_model: HuggingFaceH4/zephyr-7b-beta\n",
    "\n",
    "quantization:\n",
    "  bits: 4\n",
    "\n",
    "adapter:\n",
    "  type: lora\n",
    "\n",
    "input_features:\n",
    "  - name: keywords\n",
    "    type: text\n",
    "\n",
    "output_features:\n",
    "  - name: text\n",
    "    type: text\n",
    "\n",
    "trainer:\n",
    "    type: finetune\n",
    "    learning_rate: 0.0003\n",
    "    batch_size: 2\n",
    "    gradient_accumulation_steps: 8\n",
    "    epochs: 3\n",
    "    learning_rate_scheduler:\n",
    "      warmup_fraction: 0.01\n",
    "\n",
    "backend:\n",
    "  type: local\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Define Ludwig model object that drive model training\n",
    "model = LudwigModel(config=config, logging_level=logging.INFO)\n",
    "\n",
    "# initiate model training\n",
    "(\n",
    "    train_stats,  # dictionary containing training statistics\n",
    "    preprocessed_data,  # tuple Ludwig Dataset objects of pre-processed training data\n",
    "    output_directory,  # location of training results stored on disk\n",
    ") = model.train(\n",
    "    dataset=valid_haikus\n",
    ")\n",
    "\n",
    "# list contents of output directory\n",
    "print(\"contents of output directory:\", output_directory)\n",
    "for item in os.listdir(output_directory):\n",
    "    print(\"\\t\", item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ok, so how'd we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded HuggingFace implementation of HuggingFaceH4/zephyr-7b-beta tokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 100%|██████████| 1/1 [00:06<00:00,  6.04s/it]\n",
      "Loaded HuggingFace implementation of HuggingFaceH4/zephyr-7b-beta tokenizer\n",
      "Finished predicting in: 7.68s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dave/miniconda3/envs/llm/lib/python3.9/site-packages/ludwig/features/feature_utils.py:102: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(sequence_probabilities))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                                    text_predictions  \\\n",
       " 0  [, I, ', m, not, a, flower, ., /, I, ', m, not...   \n",
       " 1  [, I, ', m, not, gonna, lie, ., /, I, ', m, re...   \n",
       " 2  [, I, ', m, really, good, at, ., /, Data, anal...   \n",
       " \n",
       "                                   text_probabilities  \\\n",
       " 0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       " 1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       " 2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       " \n",
       "                                        text_response  text_probability  \n",
       " 0  [I'm not a flower. / I'm not a flower, I'm not...              -inf  \n",
       " 1  [I'm not gonna lie. / I'm really looking forwa...              -inf  \n",
       " 2  [I'm really good at. / Data analysis, but I'm....              -inf  ,\n",
       " 'results')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict({\"keywords\": [\"flowers\", \"trucks\", \"data analysis\"]})\n",
    "\n",
    "response = model.predict(df)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not a flower. / I'm not a flower, I'm not. / A flower, I'm not.\n",
      "I'm not gonna lie. / I'm really looking forward. / To the trucks tonight.\n",
      "I'm really good at. / Data analysis, but I'm. / Not good at math.\n"
     ]
    }
   ],
   "source": [
    "answers = response[0][\"text_response\"]\n",
    "\n",
    "for a in answers:\n",
    "    print(a[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
