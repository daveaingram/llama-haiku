Welcome to an exploration of training Large Language Models locally to write Haikus more consistently!

You'll find a handful of notebooks here which occompany the slides found here:
https://docs.google.com/presentation/d/1pEvvBIzjQVx_GZnKGiYA-aCUkSZ7yj60tukuhnjIEL0/edit?usp=sharing

The slides also reference the following links:

* Hugging Face – https://huggingface.co/
* LM Studio – https://lmstudio.ai/
* Ollama – https://ollama.ai/
* LLM Arena – https://arena.lmsys.org/
* Predibase (Ludwig, LoRAX) – https://predibase.com/ 
* Brev.dev (Notebooks, Compute) – https://brev.dev/
* Github Repo – https://github.com/daveaingram/llama-haiku 

## Usage

To use these notebooks, you'll need to install the python requirements in requirements.txt, then you should be able to run the notebooks in Jupyter Notebook.
